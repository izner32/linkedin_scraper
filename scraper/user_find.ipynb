{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIND USER'S NAME AND ACCOUNT LINKS BASED ON KEYWORD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add refresh at every error , if the error persists after 3 refresh then quit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for scraping \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# misc\n",
    "import re as re # regex \n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# accesing env file \n",
    "import os \n",
    "from dotenv import load_dotenv # to access the secret keys we've hidden in a separate file \n",
    "load_dotenv() # grab values inside env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selenium and LinkedIn Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = os.getenv(\"WEBDRIVER_PATH\")\n",
    "USERNAME = os.getenv(\"LI_USERNAME\")\n",
    "PASSWORD = os.getenv(\"LI_PASS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize web driver that would control the web browser\n",
    "ser = Service(PATH)\n",
    "op = webdriver.ChromeOptions()\n",
    "driver = webdriver.Chrome(service=ser, options=op)\n",
    "\n",
    "# website we wanted to access \n",
    "driver.get(\"https://www.linkedin.com/uas/login\")\n",
    "time.sleep(3) # added a pause to avoid getting marked as bot \n",
    "\n",
    "# login in linkedin\n",
    "email=driver.find_element(By.ID,\"username\")\n",
    "email.send_keys(USERNAME)\n",
    "password=driver.find_element(By.ID,\"password\")\n",
    "password.send_keys(PASSWORD)\n",
    "time.sleep(3)\n",
    "password.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web Scraping Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_links = []\n",
    "user_names = []\n",
    "user_location = []\n",
    "user_bio = []\n",
    "\n",
    "def user_find_scrape(search_info, max_page):\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # scroll mindlessly to avoid getting flagged as a bot\n",
    "    start=time.time()\n",
    "    lastHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        newHeight = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if newHeight == lastHeight:\n",
    "            break\n",
    "        lastHeight = newHeight\n",
    "        end=time.time()\n",
    "        if round(end-start)>20: # scrolling thru website - pretending we're not a bot for 20 seconds \n",
    "            break\n",
    "\n",
    "    # type into search bar \n",
    "    search_bar = driver.find_element(By.CLASS_NAME, \"search-global-typeahead__input\")\n",
    "    search_bar.send_keys(search_info)\n",
    "    time.sleep(5)\n",
    "    search_bar.send_keys(Keys.ENTER)\n",
    "    time.sleep(5)\n",
    "\n",
    "    # expand search result \n",
    "    try: \n",
    "        expand_result_click = driver.find_element(By.LINK_TEXT, \"See all people results\").click()\n",
    "        time.sleep(5)\n",
    "    except:\n",
    "        print(\"Expand result failure\")\n",
    "        driver.quit()\n",
    "\n",
    "    page = 0\n",
    "    while page <= max_page: # how many search result page | each page has 10 users\n",
    "        # find container for all names available in the current page  \n",
    "        expanded_page_result = driver.page_source\n",
    "        linkedin_soup = bs(expanded_page_result.encode(\"utf-8\"), \"html\")\n",
    "        linkedin_soup.prettify()\n",
    "        huge_container = linkedin_soup.find(\"ul\",{\"class\":\"reusable-search__entity-result-list\"})\n",
    "        containers = huge_container.findAll(\"li\",{\"class\":\"reusable-search__result-container\"})\n",
    "\n",
    "        # iterate thru each of the name - grab each user's specified value and append each user's value in an array \n",
    "        iterations = 0\n",
    "        nos = 5 # grab only 5 users on each page\n",
    "        for user in containers: \n",
    "            try:\n",
    "                user_name_box = user.find(\"span\",{\"class\":\"entity-result__title-text\"})\n",
    "                user_name_value = user_name_box.find(\"span\",{\"aria-hidden\":\"true\"}).get_text()\n",
    "                user_link_value = user_name_box.find(\"a\",{\"class\":\"app-aware-link\"}, href=True)[\"href\"]\n",
    "                user_location_value = user.find(\"div\",{\"class\":\"entity-result__secondary-subtitle\"}).get_text()\n",
    "                user_bio_value = user.find(\"div\",{\"class\":\"entity-result__primary-subtitle\"}).get_text()\n",
    "\n",
    "                user_links.append(user_link_value)\n",
    "                user_names.append(user_name_value)\n",
    "                user_location.append(user_location_value)\n",
    "                user_bio.append(user_bio_value)\n",
    "\n",
    "                iterations += 1\n",
    "\n",
    "                if(iterations==nos):\n",
    "                    break\n",
    "\n",
    "            except:\n",
    "                print(\"There is an error fetching users. Initiating exit.\")              \n",
    "                driver.quit()\n",
    "\n",
    "        # click next button - scroll down and wait for 30 seconds for the next button to load \n",
    "        try: \n",
    "            time.sleep(5)\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(30)\n",
    "            next_button_find = driver.find_element(By.CSS_SELECTOR, \".artdeco-pagination__button--next\")\n",
    "            next_button_find.click()\n",
    "            page += 1\n",
    "            time.sleep(5)\n",
    "        except:\n",
    "            print(\"Next button clicked error. Initiating exit.\")\n",
    "            driver.quit()\n",
    "        \n",
    "    \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_find_scrape(\"data engineer\",2) # 1st parameter - keyword | 2nd parameter - max_page, each result page only has 10 people \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing scraped data into specified file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xlsxwriter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16968/2562149159.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# save to excel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExcelWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"user_posts.xlsx\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'xlsxwriter'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_xlsxwriter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    182\u001b[0m     ):\n\u001b[0;32m    183\u001b[0m         \u001b[1;31m# Use the xlsxwriter module as the Excel writer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[1;32mfrom\u001b[0m \u001b[0mxlsxwriter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWorkbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[0mengine_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcombine_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xlsxwriter'"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\": user_names,\n",
    "    \"Location\": user_location,\n",
    "    \"Bio\": user_bio,\n",
    "    \"Link\": user_links\n",
    "}\n",
    "\n",
    "# save to csv \n",
    "df = pd.DataFrame(data)\n",
    "df.head(5)\n",
    "df.to_csv(\"user_find.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "# save to excel \n",
    "# writer = pd.ExcelWriter(\"user_find.xlsx\", engine='xlsxwriter')\n",
    "# df.to_excel(writer, index =False)\n",
    "# writer.save()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bfb4883d108fc92ac768439090a2e92bb9a1f760a54beeecfd6762b5dcd70fe3"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
